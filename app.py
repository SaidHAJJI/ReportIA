import streamlit as st
import time
from datetime import datetime
from google import genai
from google.genai import types

# Configuration de la page
st.set_page_config(page_title="Elite Editorial", page_icon="‚öñÔ∏è", layout="centered")

# --- STYLE CSS POUR MOBILE ---
st.markdown(\"\"\"
    <style>
    .stButton>button { width: 100%; border-radius: 20px; height: 3em; background-color: #007bff; color: white; }
    .stTextInput>div>div>input { border-radius: 15px; }
    </style>
    \"\"\", unsafe_allow_html=True)

st.title("‚öñÔ∏è Elite Editorial Engine")
st.caption("Moteur d'analyse g√©opolitique et strat√©gique multi-agents")

# --- CONFIGURATION API ---
with st.sidebar:
    st.header("üîë Param√®tres")
    api_key = st.text_input("Cl√© API Gemini", type="password")
    langue = st.selectbox("Langue de r√©daction", ["Fran√ßais", "Anglais", "Arabe"])
    st.divider()
    st.info("D√©ploy√© via Streamlit Cloud pour Android.")

if not api_key:
    st.warning("Veuillez entrer votre cl√© API Gemini dans le menu lat√©ral pour activer les agents.")
    st.stop()

# Initialisation Client
client = genai.Client(api_key=api_key)
MODEL_FLASH = "models/gemini-flash-latest"
MODEL_PRO = "models/gemini-pro-latest"
search_tool = types.Tool(google_search=types.GoogleSearch())

# --- DICTIONNAIRE DES 9 EXPERTS ---
PERSONNALITES = {
    "scout": {"role": "Le Scout", "model": MODEL_FLASH, "instr": "Cherche les faits r√©cents via Google Search."},
    "expert_legal": {"role": "L'Expert Juridique", "model": MODEL_PRO, "instr": "Analyse le cadre r√©glementaire."},
    "expert_eco": {"role": "L'√âconomiste", "model": MODEL_PRO, "instr": "Analyse les impacts financiers."},
    "optimist": {"role": "Le Visionnaire", "model": MODEL_FLASH, "instr": "D√©fends l'innovation."},
    "skeptic": {"role": "Le Critique", "model": MODEL_FLASH, "instr": "Souligne les risques."},
    "provocateur": {"role": "Le R√©dacteur en Chef", "model": MODEL_PRO, "instr": "Identifie une faille logique."},
    "analyst": {"role": "L'Analyste", "model": MODEL_FLASH, "instr": "Calcule la tension du d√©bat (-10 √† +10)."},
    "checker": {"role": "Le Fact-Checker", "model": MODEL_FLASH, "instr": "V√©rifie les faits via Search."},
    "editor": {"role": "Grand √âditorialiste", "model": MODEL_PRO, "instr": "R√©dige une enqu√™te de prestige type Le Monde/NYT."}
}

def ask_agent(agent_key, prompt, use_search=False):
    p = PERSONNALITES[agent_key]
    config = types.GenerateContentConfig(
        system_instruction=f"Tu es {p['role']}. {p['instr']} R√âPONDS EXCLUSIVEMENT EN {langue.upper()}.",
        tools=[search_tool] if use_search else []
    )
    return client.models.generate_content(model=p["model"], config=config, contents=prompt).text

# --- INTERFACE DE SAISIE ---
sujet = st.text_input("üìù Sujet de l'analyse :", placeholder="ex: L'avenir de l'√©nergie nucl√©aire...")

if st.button("üöÄ Lancer l'Analyse √âlite"):
    if not sujet:
        st.error("Merci de saisir un sujet.")
    else:
        with st.status("üß† Les agents collaborent...", expanded=True) as status:
            # Workflow
            st.write("üîé Intelligence Unit en cours...")
            intel = ask_agent("scout", f"Donne les faits r√©cents sur {sujet}", use_search=True)
            
            st.write("‚öñÔ∏è Expertise L√©gale & √âco...")
            leg = ask_agent("expert_legal", f"Enjeux r√©glementaires : {intel}")
            eco = ask_agent("expert_eco", f"Impact financier : {intel}")
            
            st.write("‚öîÔ∏è D√©bat et Provocation...")
            o1 = ask_agent("optimist", f"Opportunit√©s : {intel} {leg} {eco}")
            s1 = ask_agent("skeptic", f"Risques : {o1}")
            angle = ask_agent("provocateur", f"Angle mort : {o1} vs {s1}")
            
            st.write("üìä Analyse de tension...")
            tension = ask_agent("analyst", f"Score de tension : {o1} {s1} {angle}")
            
            st.write("‚úçÔ∏è R√©daction finale...")
            report = ask_agent("editor", f"R√©dige l'√©ditorial final sur {sujet} bas√© sur : {intel}, {o1}, {s1}, {angle}, {tension}")
            
            status.update(label="Analyse termin√©e !", state="complete")

        st.markdown("---")
        st.markdown(report)
        st.sidebar.download_button("üì• T√©l√©charger (Markdown)", report, f"rapport_{sujet}.md")
\"\"\"

# --- CR√âATION PHYSIQUE DES FICHIERS (Si ex√©cut√© localement) ---
with open("requirements.txt", "w") as f: f.write(requirements)
with open("app.py", "w") as f: f.write(app_code)

print("‚úÖ Fichiers 'app.py' et 'requirements.txt' g√©n√©r√©s avec succ√®s pour votre d√©p√¥t GitHub.")